{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gajar\\Desktop\\Investigación DA LLM\\dashboard\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"dair-ai/emotion\", \"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds[\"validation\"].to_pandas()\n",
    "df.to_csv(\"../data/emotion_val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gajar\\Desktop\\Investigación DA LLM\\dashboard\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\gajar\\.cache\\huggingface\\hub\\models--roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\gajar\\Desktop\\Investigación DA LLM\\dashboard\\env\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py:610: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      " 25%|██▌       | 1/4 [00:13<00:39, 13.05s/it]\n",
      " 75%|███████▌  | 3/4 [00:13<00:03,  3.51s/it]\n",
      "100%|██████████| 4/4 [00:13<00:00,  2.34s/it]\n",
      "100%|██████████| 4/4 [00:13<00:00,  3.38s/it]\n",
      "\n",
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Epoch 1 of 2:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "\n",
      "Running Epoch 1 of 2:   0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.9130:   0%|          | 0/250 [00:09<?, ?it/s]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.9130:   0%|          | 1/250 [00:20<1:26:03, 20.74s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8731:   0%|          | 1/250 [00:39<1:26:03, 20.74s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8731:   1%|          | 2/250 [00:50<1:47:43, 26.06s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7081:   1%|          | 2/250 [00:57<1:47:43, 26.06s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7081:   1%|          | 3/250 [01:07<1:30:05, 21.89s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.9786:   1%|          | 3/250 [01:12<1:30:05, 21.89s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.9786:   2%|▏         | 4/250 [01:23<1:20:04, 19.53s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8965:   2%|▏         | 4/250 [01:28<1:20:04, 19.53s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8965:   2%|▏         | 5/250 [01:37<1:11:47, 17.58s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.9416:   2%|▏         | 5/250 [01:42<1:11:47, 17.58s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.9416:   2%|▏         | 6/250 [01:51<1:06:34, 16.37s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.9111:   2%|▏         | 6/250 [01:56<1:06:34, 16.37s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.9111:   3%|▎         | 7/250 [02:05<1:02:50, 15.52s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8890:   3%|▎         | 7/250 [02:10<1:02:50, 15.52s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8890:   3%|▎         | 8/250 [02:19<1:00:23, 14.97s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7475:   3%|▎         | 8/250 [02:24<1:00:23, 14.97s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7475:   4%|▎         | 9/250 [02:33<59:05, 14.71s/it]  \u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8542:   4%|▎         | 9/250 [02:43<59:05, 14.71s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8542:   4%|▍         | 10/250 [03:00<1:14:38, 18.66s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7999:   4%|▍         | 10/250 [03:08<1:14:38, 18.66s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7999:   4%|▍         | 11/250 [03:19<1:14:42, 18.76s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8268:   4%|▍         | 11/250 [03:24<1:14:42, 18.76s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8268:   5%|▍         | 12/250 [03:33<1:08:31, 17.27s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7252:   5%|▍         | 12/250 [03:38<1:08:31, 17.27s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7252:   5%|▌         | 13/250 [03:47<1:04:37, 16.36s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7723:   5%|▌         | 13/250 [03:53<1:04:37, 16.36s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7723:   6%|▌         | 14/250 [04:02<1:02:49, 15.97s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8617:   6%|▌         | 14/250 [04:08<1:02:49, 15.97s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8617:   6%|▌         | 15/250 [04:19<1:03:10, 16.13s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6718:   6%|▌         | 15/250 [04:24<1:03:10, 16.13s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6718:   6%|▋         | 16/250 [04:33<1:00:30, 15.52s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6058:   6%|▋         | 16/250 [04:38<1:00:30, 15.52s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6058:   7%|▋         | 17/250 [04:47<58:44, 15.13s/it]  \u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7566:   7%|▋         | 17/250 [04:52<58:44, 15.13s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7566:   7%|▋         | 18/250 [05:01<56:53, 14.71s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.5976:   7%|▋         | 18/250 [05:06<56:53, 14.71s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.5976:   8%|▊         | 19/250 [05:15<55:56, 14.53s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8609:   8%|▊         | 19/250 [05:20<55:56, 14.53s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8609:   8%|▊         | 20/250 [05:29<55:06, 14.38s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7707:   8%|▊         | 20/250 [05:34<55:06, 14.38s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7707:   8%|▊         | 21/250 [05:43<54:26, 14.26s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6843:   8%|▊         | 21/250 [05:48<54:26, 14.26s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6843:   9%|▉         | 22/250 [05:57<53:41, 14.13s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6374:   9%|▉         | 22/250 [06:02<53:41, 14.13s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6374:   9%|▉         | 23/250 [06:11<53:05, 14.03s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7562:   9%|▉         | 23/250 [06:17<53:05, 14.03s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7562:  10%|▉         | 24/250 [06:27<55:06, 14.63s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7523:  10%|▉         | 24/250 [06:32<55:06, 14.63s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7523:  10%|█         | 25/250 [06:42<55:17, 14.74s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8546:  10%|█         | 25/250 [06:48<55:17, 14.74s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8546:  10%|█         | 26/250 [06:57<55:53, 14.97s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6064:  10%|█         | 26/250 [07:03<55:53, 14.97s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6064:  11%|█         | 27/250 [07:14<57:08, 15.38s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7158:  11%|█         | 27/250 [07:21<57:08, 15.38s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7158:  11%|█         | 28/250 [07:30<58:15, 15.74s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7052:  11%|█         | 28/250 [07:36<58:15, 15.74s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7052:  12%|█▏        | 29/250 [07:46<57:39, 15.66s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.5282:  12%|█▏        | 29/250 [07:52<57:39, 15.66s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.5282:  12%|█▏        | 30/250 [08:02<58:18, 15.90s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8664:  12%|█▏        | 30/250 [08:09<58:18, 15.90s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8664:  12%|█▏        | 31/250 [08:17<57:28, 15.75s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6051:  12%|█▏        | 31/250 [08:23<57:28, 15.75s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6051:  13%|█▎        | 32/250 [08:33<56:37, 15.58s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6943:  13%|█▎        | 32/250 [08:38<56:37, 15.58s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6943:  13%|█▎        | 33/250 [08:46<54:10, 14.98s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7055:  13%|█▎        | 33/250 [08:52<54:10, 14.98s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7055:  14%|█▎        | 34/250 [09:00<53:04, 14.75s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6256:  14%|█▎        | 34/250 [09:05<53:04, 14.75s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6256:  14%|█▍        | 35/250 [09:14<51:07, 14.27s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    2.0392:  14%|█▍        | 35/250 [09:19<51:07, 14.27s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    2.0392:  14%|█▍        | 36/250 [09:27<50:01, 14.02s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.4867:  14%|█▍        | 36/250 [09:32<50:01, 14.02s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.4867:  15%|█▍        | 37/250 [09:41<49:23, 13.91s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6667:  15%|█▍        | 37/250 [09:46<49:23, 13.91s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6667:  15%|█▌        | 38/250 [09:57<51:24, 14.55s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7392:  15%|█▌        | 38/250 [10:03<51:24, 14.55s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7392:  16%|█▌        | 39/250 [10:14<53:53, 15.32s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.5614:  16%|█▌        | 39/250 [10:20<53:53, 15.32s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.5614:  16%|█▌        | 40/250 [10:31<55:31, 15.86s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7123:  16%|█▌        | 40/250 [10:37<55:31, 15.86s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7123:  16%|█▋        | 41/250 [10:47<55:40, 15.98s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6527:  16%|█▋        | 41/250 [10:53<55:40, 15.98s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6527:  17%|█▋        | 42/250 [11:04<55:44, 16.08s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.2956:  17%|█▋        | 42/250 [11:10<55:44, 16.08s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.2956:  17%|█▋        | 43/250 [11:20<55:53, 16.20s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.3852:  17%|█▋        | 43/250 [11:26<55:53, 16.20s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.3852:  18%|█▊        | 44/250 [11:37<56:14, 16.38s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8680:  18%|█▊        | 44/250 [11:43<56:14, 16.38s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8680:  18%|█▊        | 45/250 [11:53<56:00, 16.39s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.4297:  18%|█▊        | 45/250 [11:59<56:00, 16.39s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.4297:  18%|█▊        | 46/250 [12:09<54:52, 16.14s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.5211:  18%|█▊        | 46/250 [12:14<54:52, 16.14s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.5211:  19%|█▉        | 47/250 [12:24<53:46, 15.89s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    2.0565:  19%|█▉        | 47/250 [12:29<53:46, 15.89s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    2.0565:  19%|█▉        | 48/250 [12:39<51:59, 15.44s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.9408:  19%|█▉        | 48/250 [12:44<51:59, 15.44s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.9408:  20%|█▉        | 49/250 [12:54<51:20, 15.32s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.4250:  20%|█▉        | 49/250 [12:59<51:20, 15.32s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.4250:  20%|██        | 50/250 [13:10<52:07, 15.64s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7998:  20%|██        | 50/250 [13:15<52:07, 15.64s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7998:  20%|██        | 51/250 [13:25<51:03, 15.40s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6431:  20%|██        | 51/250 [13:30<51:03, 15.40s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6431:  21%|██        | 52/250 [13:40<50:16, 15.23s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8001:  21%|██        | 52/250 [13:45<50:16, 15.23s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8001:  21%|██        | 53/250 [13:56<51:33, 15.70s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.3692:  21%|██        | 53/250 [14:02<51:33, 15.70s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.3692:  22%|██▏       | 54/250 [14:13<52:18, 16.01s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.5682:  22%|██▏       | 54/250 [14:20<52:18, 16.01s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.5682:  22%|██▏       | 55/250 [14:31<53:45, 16.54s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7682:  22%|██▏       | 55/250 [14:38<53:45, 16.54s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7682:  22%|██▏       | 56/250 [14:48<54:01, 16.71s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6167:  22%|██▏       | 56/250 [14:54<54:01, 16.71s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6167:  23%|██▎       | 57/250 [15:05<54:04, 16.81s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.5372:  23%|██▎       | 57/250 [15:11<54:04, 16.81s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.5372:  23%|██▎       | 58/250 [15:22<53:29, 16.72s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7711:  23%|██▎       | 58/250 [15:28<53:29, 16.72s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7711:  24%|██▎       | 59/250 [15:39<53:37, 16.84s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.4896:  24%|██▎       | 59/250 [15:45<53:37, 16.84s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.4896:  24%|██▍       | 60/250 [15:56<53:22, 16.85s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.3697:  24%|██▍       | 60/250 [16:02<53:22, 16.85s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.3697:  24%|██▍       | 61/250 [16:12<52:39, 16.72s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.3077:  24%|██▍       | 61/250 [16:18<52:39, 16.72s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.3077:  25%|██▍       | 62/250 [16:28<52:08, 16.64s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.3863:  25%|██▍       | 62/250 [16:34<52:08, 16.64s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.3863:  25%|██▌       | 63/250 [16:44<50:55, 16.34s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.5570:  25%|██▌       | 63/250 [16:50<50:55, 16.34s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.5570:  26%|██▌       | 64/250 [17:00<50:08, 16.18s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.4540:  26%|██▌       | 64/250 [17:06<50:08, 16.18s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.4540:  26%|██▌       | 65/250 [17:15<49:18, 15.99s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8434:  26%|██▌       | 65/250 [17:21<49:18, 15.99s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.8434:  26%|██▋       | 66/250 [17:30<47:16, 15.42s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    0.9831:  26%|██▋       | 66/250 [17:35<47:16, 15.42s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    0.9831:  27%|██▋       | 67/250 [17:44<46:20, 15.20s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7157:  27%|██▋       | 67/250 [17:49<46:20, 15.20s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7157:  27%|██▋       | 68/250 [17:59<45:23, 14.96s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.4100:  27%|██▋       | 68/250 [18:04<45:23, 14.96s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.4100:  28%|██▊       | 69/250 [18:12<43:39, 14.47s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7358:  28%|██▊       | 69/250 [18:17<43:39, 14.47s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.7358:  28%|██▊       | 70/250 [18:25<42:23, 14.13s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.5005:  28%|██▊       | 70/250 [18:30<42:23, 14.13s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.5005:  28%|██▊       | 71/250 [18:39<42:08, 14.13s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.0869:  28%|██▊       | 71/250 [18:45<42:08, 14.13s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.0869:  29%|██▉       | 72/250 [18:54<42:15, 14.25s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6217:  29%|██▉       | 72/250 [18:59<42:15, 14.25s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.6217:  29%|██▉       | 73/250 [19:09<42:33, 14.43s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.1879:  29%|██▉       | 73/250 [19:14<42:33, 14.43s/it]\u001b[A\n",
      "\n",
      "Epochs 1/2. Running Loss:    1.1879:  30%|██▉       | 74/250 [19:25<44:05, 15.03s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "!python ../scripts/lambada/train_cls.py  \\\n",
    "    --train_data_path ../data/emotion_val.csv \\\n",
    "    --val_data_path ../data/emotion_val.csv \\\n",
    "    --output_dir ../model/lambada/cls \\\n",
    "    --device cpu \\\n",
    "    --num_epoch 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
